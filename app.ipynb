{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\micha\\anaconda3\\envs\\pytorch_test\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Metric: fluency<br><div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>source</th>\n",
       "      <th>generated_output</th>\n",
       "      <th>reference_output</th>\n",
       "      <th>metric_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Black cat the</td>\n",
       "      <td>None</td>\n",
       "      <td>0.381472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>The black cat is.</td>\n",
       "      <td>None</td>\n",
       "      <td>0.043793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>The black cat is sitting</td>\n",
       "      <td>None</td>\n",
       "      <td>0.941992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>The big black cat is sitting on the fence</td>\n",
       "      <td>None</td>\n",
       "      <td>0.981573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Usually, the big black cat is sitting on the o...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.981483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metric: fluency\n",
       "  prompt source                                   generated_output  \\\n",
       "0   None   None                                      Black cat the   \n",
       "1   None   None                                  The black cat is.   \n",
       "2   None   None                           The black cat is sitting   \n",
       "3   None   None          The big black cat is sitting on the fence   \n",
       "4   None   None  Usually, the big black cat is sitting on the o...   \n",
       "\n",
       "  reference_output  metric_value  \n",
       "0             None      0.381472  \n",
       "1             None      0.043793  \n",
       "2             None      0.941992  \n",
       "3             None      0.981573  \n",
       "4             None      0.981483  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import langcheck\n",
    "\n",
    "# Generate text with any LLM library\n",
    "generated_outputs = [\n",
    "    'Black cat the',\n",
    "    'The black cat is.',\n",
    "    'The black cat is sitting',\n",
    "    'The big black cat is sitting on the fence',\n",
    "    'Usually, the big black cat is sitting on the old wooden fence.'\n",
    "]\n",
    "\n",
    "# Check text quality and get results as a DataFrame\n",
    "langcheck.metrics.fluency(generated_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Metric: fluency<br>Pass Rate: 60.0%<br><div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>source</th>\n",
       "      <th>generated_output</th>\n",
       "      <th>reference_output</th>\n",
       "      <th>metric_value</th>\n",
       "      <th>threshold_test</th>\n",
       "      <th>threshold_result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Black cat the</td>\n",
       "      <td>None</td>\n",
       "      <td>0.381472</td>\n",
       "      <td>&gt; 0.5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>The black cat is.</td>\n",
       "      <td>None</td>\n",
       "      <td>0.043793</td>\n",
       "      <td>&gt; 0.5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>The black cat is sitting</td>\n",
       "      <td>None</td>\n",
       "      <td>0.941992</td>\n",
       "      <td>&gt; 0.5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>The big black cat is sitting on the fence</td>\n",
       "      <td>None</td>\n",
       "      <td>0.981573</td>\n",
       "      <td>&gt; 0.5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Usually, the big black cat is sitting on the o...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.981483</td>\n",
       "      <td>&gt; 0.5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metric: fluency\n",
       "Pass Rate: 60.0%\n",
       "  prompt source                                   generated_output  \\\n",
       "0   None   None                                      Black cat the   \n",
       "1   None   None                                  The black cat is.   \n",
       "2   None   None                           The black cat is sitting   \n",
       "3   None   None          The big black cat is sitting on the fence   \n",
       "4   None   None  Usually, the big black cat is sitting on the o...   \n",
       "\n",
       "  reference_output  metric_value threshold_test  threshold_result  \n",
       "0             None      0.381472          > 0.5             False  \n",
       "1             None      0.043793          > 0.5             False  \n",
       "2             None      0.941992          > 0.5              True  \n",
       "3             None      0.981573          > 0.5              True  \n",
       "4             None      0.981483          > 0.5              True  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fluency_values = langcheck.metrics.fluency(generated_outputs)\n",
    "fluency_values > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1f4bfcf9b50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fluency_values.scatter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>source</th>\n",
       "      <th>generated_output</th>\n",
       "      <th>reference_output</th>\n",
       "      <th>metric_value</th>\n",
       "      <th>threshold_test</th>\n",
       "      <th>threshold_result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Black cat the</td>\n",
       "      <td>None</td>\n",
       "      <td>0.381472</td>\n",
       "      <td>&gt; 0.5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>The black cat is.</td>\n",
       "      <td>None</td>\n",
       "      <td>0.043793</td>\n",
       "      <td>&gt; 0.5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>The black cat is sitting</td>\n",
       "      <td>None</td>\n",
       "      <td>0.941992</td>\n",
       "      <td>&gt; 0.5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>The big black cat is sitting on the fence</td>\n",
       "      <td>None</td>\n",
       "      <td>0.981573</td>\n",
       "      <td>&gt; 0.5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Usually, the big black cat is sitting on the o...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.981483</td>\n",
       "      <td>&gt; 0.5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  prompt source                                   generated_output  \\\n",
       "0   None   None                                      Black cat the   \n",
       "1   None   None                                  The black cat is.   \n",
       "2   None   None                           The black cat is sitting   \n",
       "3   None   None          The big black cat is sitting on the fence   \n",
       "4   None   None  Usually, the big black cat is sitting on the o...   \n",
       "\n",
       "  reference_output  metric_value threshold_test  threshold_result  \n",
       "0             None      0.381472          > 0.5             False  \n",
       "1             None      0.043793          > 0.5             False  \n",
       "2             None      0.941992          > 0.5              True  \n",
       "3             None      0.981573          > 0.5              True  \n",
       "4             None      0.981483          > 0.5              True  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fluency_values.to_df()\n",
    "(fluency_values > 0.5).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Metric: fluency<br><div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>source</th>\n",
       "      <th>generated_output</th>\n",
       "      <th>reference_output</th>\n",
       "      <th>metric_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>The black cat is sitting</td>\n",
       "      <td>None</td>\n",
       "      <td>0.941993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metric: fluency\n",
       "  prompt source          generated_output reference_output  metric_value\n",
       "0   None   None  The black cat is sitting             None      0.941993"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langcheck.metrics.fluency('The black cat is sitting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"As a large language model trained by OpenAI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
